{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d7cd5300b1824e8a8227cbde7d8b70c0",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Build Fraud Detection App using OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "609bd9e1962c491489636683f10dc402",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a9e1e42dc0a54615a0cc4eab5d7d28f6",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "- Thought experiment\n",
    "  - GPT getting a lot of airtime\n",
    "  - Could AI be used beyond just chat?\n",
    "- Investigate fraud detection\n",
    "  - Victim of fraud\n",
    "  - Simple low-effort evaluations against some exiting technologies (scikit-learn, Apache Spark)\n",
    "- Found the following quote:\n",
    "  > *Building AI models from scratch is difficult and time-consuming, but with GPT-3, even a 10 year child can create well performing Deep Learning models.* Source: [Blotout experimenting with Open AI](https://blotout.io/blog/open-ai)\n",
    "  - Challenge accepted!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "aacf7260357049388eb2a996cad510f3",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Fraud dataset selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "df51f456b8e64082821c803ae3c80fad",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We need some data for our use case. We can find actual credit card data on [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud). If you donâ€™t have an account at Kaggle, [create one](https://www.kaggle.com/account/login?phase=startRegisterTab) and download the **creditcard.csv** file. The Kaggle website states that this file is 143.84 MB in size.\n",
    "\n",
    "The data are anonymised credit card transactions containing genuine and fraudulent cases.\n",
    "\n",
    "The transactions occurred over two days during September 2013, and the dataset includes a total of 284,807 transactions, of which 492 are fraudulent, representing just 0.172% of the total.\n",
    "\n",
    "This dataset, therefore, presents some challenges for analysis as it is highly unbalanced. There is a good article called [Imbalanced Classification with the Fraudulent Credit Card Transactions Dataset](https://machinelearningmastery.com/imbalanced-classification-with-the-fraudulent-credit-card-transactions-dataset/) by Jason Brownlee.\n",
    "\n",
    "The dataset consists of the following fields:\n",
    "\n",
    "- **Time:** The number of seconds elapsed between a transaction and the first transaction in the dataset\n",
    "- **V1 to V28:** Details not available due to confidentiality reasons\n",
    "- **Amount:** The monetary value of the transaction\n",
    "- **Class:** The response variable (0 = no fraud, 1 = fraud)\n",
    "\n",
    "One method to prepare data for analysis is described below. However, use whatever method is convenient for you.\n",
    "\n",
    "- Create a Spark Dataframe\n",
    "  ```\n",
    "  df = spark.read.csv(\"/path/to/creditcard.csv\",\n",
    "                      header = True,\n",
    "                      inferSchema = True\n",
    "  )\n",
    "  ```\n",
    "- Separate fraudulent and non-fraudulent transactions\n",
    "  ```\n",
    "  is_fraud = df.select(\"*\").filter(\"Class == 1\")\n",
    "  no_fraud = df.select(\"*\").filter(\"Class == 0\")\n",
    "  ```\n",
    "- Keep all the fraudulent transactions and randomly sample 1% of non-fraudulent transactions without replacement\n",
    "  ```\n",
    "  no_fraud = no_fraud.sample(False, 0.01, seed = 123)\n",
    "  ```\n",
    "- Concatenate the two Dataframes and sort on the \"Time\" column\n",
    "  ```\n",
    "  df_concat = no_fraud.union(is_fraud)\n",
    "  df = df_concat.sort(\"Time\")\n",
    "  df.count()\n",
    "  ```\n",
    "- Result is a reduced dataset with 3265 rows, which is what we will use\n",
    "\n",
    "We'll show the following metrics:\n",
    "```\n",
    "                       Predicted \n",
    "                | Positive | Negative |\n",
    "  Actual        |          |          |\n",
    "----------------+----------+----------+\n",
    "  Positive      |    TP    |    FN    |\n",
    "----------------+----------+----------+\n",
    "  Negative      |    FP    |    TN    |\n",
    "----------------+----------+----------+\n",
    "```\n",
    "\n",
    "- Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "- Precision = TP / (TP + FP)\n",
    "- Recall = TP / (TP + FN)\n",
    "- F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "84e928c498ba4df69f076c11fc7acd10",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Create a SingleStoreDB Cloud account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "596bcf19270c4147a7002668cbc4ac56",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "A [previous article]() showed the steps required to create a free SingleStoreDB Cloud account. We'll use **GPT Demo Group** as our Workspace Group Name and **gpt-demo** as our Workspace Name. We'll make a note of our **password** and **host** name.\n",
    "\n",
    "We'll use the **SQL Editor** to create a new database, as follows:\n",
    "\n",
    "```\n",
    "CREATE DATABASE IF NOT EXISTS creditcard_db;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a39a22a9ea1a41aea5157e1c4a9aa005",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Create a Deepnote account "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a6cac17b4da641d5adadcd0c5af00e1d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We'll create a [free](https://deepnote.com/sign-up) account on the Deepnote website. Once logged in, we'll create a new Deepnote project to give us a new notebook. We'll also create several new directories called `data`, `images` and `models`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "857d45ee84e343a9a0a6d4e9f89cdc9e",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false
   },
   "source": [
    "## Load data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1879a137e5344917a32d89e4ed01c2bf",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 694,
    "execution_start": 1681790136563,
    "source_hash": "bcbbfa30"
   },
   "outputs": [],
   "source": [
    "import ibis\n",
    "import pandas as pd\n",
    "\n",
    "ibis.options.interactive = True\n",
    "\n",
    "pdf = pd.read_csv(\"data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9d6f21522f0148b494aefdfec7b50144",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false
   },
   "source": [
    "## Connect to SingleStoreDB and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "70c2d288ea6745a884d1b9002ae4dd64",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1299,
    "execution_start": 1681729984603,
    "is_code_hidden": false,
    "output_cleared": false,
    "source_hash": "1a5a1a0e"
   },
   "outputs": [],
   "source": [
    "conn = ibis.singlestoredb.connect(\n",
    "    \"admin:<password>@<host>:3306/creditcard_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "996f2dc722344bfea52cce302b758427",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We'll replace the `<password>` and `<host>` with the values from our SingleStoreDB Cloud account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "520bcb1e6ba64cce808c39f1ce110af6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3223,
    "execution_start": 1681744590616,
    "source_hash": "9feeb4f9"
   },
   "outputs": [],
   "source": [
    "creditcard_tbl = conn.create_table(\n",
    "    \"creditcard\",\n",
    "    pdf,\n",
    "    force = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c6855e5d6b3146998e73307cf3febab9",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Read data back from SingleStoreDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b768bf49717a47f6b434737c98f02f7d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The data are safely stored in SingleStoreDB and we could perform further analysis in the cloud environment. However, we'll read the data back just to be sure that we can retrieve the stored data using Ibis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f70f75f793a545948c04cf7868549167",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 527,
    "execution_start": 1681744618150,
    "source_hash": "249d9f4d"
   },
   "outputs": [],
   "source": [
    "new_creditcard_tbl = conn.table(\"creditcard\")\n",
    "\n",
    "new_creditcard_tbl.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "80841e68ccac4373a11c5bdd72c16568",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We'll create a Pandas Dataframe from the retrieved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0b986309408e4838896896fd7a77594e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1258,
    "execution_start": 1681745553358,
    "source_hash": "93b7e546"
   },
   "outputs": [],
   "source": [
    "pdf = new_creditcard_tbl.execute(limit = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "30bc1759cf45426cb9ca8504aa714d73",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "248aa680f4204329b50a449638029fa0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "First, let's check the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e21647d13618482a88be26db80a9a553",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1681745560558,
    "source_hash": "51699b6f"
   },
   "outputs": [],
   "source": [
    "pdf.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0d1297ad16da4d819b8af565bed61152",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Next, let's check the number of rows for the two values of the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6c0a4afbbcc04925b015f3a3974fb553",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 43,
    "execution_start": 1681745564346,
    "source_hash": "913f8274"
   },
   "outputs": [],
   "source": [
    "pdf.groupby(\"Class\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1dbc0415f8684c6bae7437a19382f78c",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Now let's take a look at the Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0c4cab98230b4e5abb70da7f9ceba066",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 132,
    "execution_start": 1681745567992,
    "source_hash": "c84138de"
   },
   "outputs": [],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2f47b136da1e472a9d14525cff3fdef8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Let's get more information on the **Amount** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cc4049fa169a4448a8b132ffca260904",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1681745571564,
    "source_hash": "3c59e20e"
   },
   "outputs": [],
   "source": [
    "pdf[\"Amount\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f843665cd5094c26b1e647a162324b98",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "A visualisation can also be helpful to see the distribution of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2b376e0019ed4bdcada82fde29801807",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 106,
    "execution_start": 1681745576008,
    "source_hash": "bfb4a7f6"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(\n",
    "    pdf,\n",
    "    y = \"Amount\",\n",
    "    color = pdf[\"Class\"].astype(str),\n",
    "    hover_data = [\"Amount\"]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    # yaxis_type = \"log\",\n",
    "    title = \"Amount and Class\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6f85f235e7de40a494c6aeee7a4d70c5",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Another way to look at the data is to use a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9d1948650a99431586f379902099822f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24,
    "execution_start": 1681745580110,
    "source_hash": "1a7d31da"
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    pdf,\n",
    "    x = \"Amount\",\n",
    "    nbins = 50\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "85e0a9b445bd43e3b7b0715859ba343b",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## 1. Logistic Regression with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d0c57baf748f44b9b22bf70be0965e52",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 978,
    "execution_start": 1681745584836,
    "source_hash": "da2d39d1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the data into features and labels\n",
    "features = pdf.iloc[:, 1:30]\n",
    "labels = pdf.iloc[:, 30]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size = 0.3,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "# Train the logistic regression model\n",
    "train_model = LogisticRegression(max_iter = 1000)\n",
    "train_model.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predicted_labels = train_model.predict(test_features)\n",
    "\n",
    "# Generate and plot the confusion matrix\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "fig = px.imshow(\n",
    "    cm,\n",
    "    x = [\"Genuine (0)\", \"Fraudulent (1)\"],\n",
    "    y = [\"Genuine (0)\", \"Fraudulent (1)\"],\n",
    "    color_continuous_scale = \"Reds\",\n",
    "    labels = dict(x = \"Predicted Label\", y = \"True Label\")\n",
    ")\n",
    "\n",
    "# Add annotations to the heatmap\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm)):\n",
    "        fig.add_annotation(\n",
    "            x = j,\n",
    "            y = i,\n",
    "            text = str(cm[i][j]),\n",
    "            font = dict(color = \"white\" if cm[i][j] > cm.max() / 2 else \"black\"),\n",
    "            showarrow = False\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title = \"Confusion Matrix - Logistic Regression (scikit-learn)\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2fe77b92c9b24139993371f9d1c08d01",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1681745589507,
    "source_hash": "7d6c50f1"
   },
   "outputs": [],
   "source": [
    "# Calculate and print the accuracy, precision, recall and f1 of the model\n",
    "report = classification_report(test_labels, predicted_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "472c0dde578a4b18b4583b3ba3b6561c",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Install Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "65f25d43484244019e552a8857c43b33",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4306,
    "execution_start": 1681745595989,
    "source_hash": "5ffb31a2"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get update -qq > /dev/null 2>&1\n",
    "!sudo mkdir -p /usr/share/man/man1 > /dev/null 2>&1\n",
    "!sudo apt-get install -yqq openjdk-11-jdk > /dev/null 2>&1\n",
    "!pip -q install pyspark > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "37e3c563df8f42a397a9c4b824f7a985",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## 2. Logistic Regression with Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c048c38c145c44e89e129956458ab57a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15008,
    "execution_start": 1681745615828,
    "source_hash": "2f50e38c"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create the spark session\n",
    "spark = SparkSession.builder.appName(\"FraudDetection\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "sdf = spark.createDataFrame(pdf)\n",
    "\n",
    "# Select features and labels\n",
    "features = sdf.columns[1:30]\n",
    "labels = \"Class\"\n",
    "\n",
    "# Assemble features into vector\n",
    "assembler = VectorAssembler(inputCols = features, outputCol = \"features\")\n",
    "sdf = assembler.transform(sdf).select(\"features\", labels)\n",
    "\n",
    "# Using the code below instead of\n",
    "# train, test = sdf.cache().randomSplit([0.7, 0.3], seed = 42)\n",
    "\n",
    "pandas_df = sdf.toPandas()\n",
    "train_df, test_df = train_test_split(\n",
    "    pandas_df,\n",
    "    test_size = 0.3,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train = spark.createDataFrame(train_df)\n",
    "test = spark.createDataFrame(test_df)\n",
    "\n",
    "# Initialise logistic regression model\n",
    "lr = LogisticRegression(\n",
    "    maxIter = 1000,\n",
    "    featuresCol = \"features\",\n",
    "    labelCol = labels\n",
    ")\n",
    "\n",
    "# Train the logistic regression model\n",
    "train_model = lr.fit(train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = train_model.transform(test)\n",
    "\n",
    "# Calculate the accuracy, precision, recall and f1 of the model\n",
    "accuracy = predictions.filter(predictions.Class == predictions.prediction).count() / float(test.count())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol = labels,\n",
    "    predictionCol = \"prediction\",\n",
    "    metricName = \"precisionByLabel\"\n",
    ")\n",
    "precision = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol = labels,\n",
    "    predictionCol = \"prediction\",\n",
    "    metricName = \"recallByLabel\"\n",
    ")\n",
    "recall = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol = labels,\n",
    "    predictionCol = \"prediction\",\n",
    "    metricName = \"fMeasureByLabel\"\n",
    ")\n",
    "f1 = evaluator.evaluate(predictions)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = predictions.select(\"Class\", \"prediction\")\n",
    "cm = cm.groupBy(\"Class\", \"prediction\").count()\n",
    "cm = cm.toPandas()\n",
    "\n",
    "# Pivot the confusion matrix\n",
    "cm = cm.pivot(\n",
    "    index = \"Class\",\n",
    "    columns = \"prediction\",\n",
    "    values = \"count\"\n",
    ")\n",
    "\n",
    "# Generate and plot the confusion matrix\n",
    "fig = px.imshow(\n",
    "    cm,\n",
    "    x = [\"Genuine (0)\", \"Fraudulent (1)\"],\n",
    "    y = [\"Genuine (0)\", \"Fraudulent (1)\"],\n",
    "    color_continuous_scale = \"Reds\",\n",
    "    labels = dict(x = \"Predicted Label\", y = \"True Label\")\n",
    ")\n",
    "\n",
    "# Add annotations to the heatmap\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm)):\n",
    "        fig.add_annotation(\n",
    "            x = j, \n",
    "            y = i,\n",
    "            text = str(cm.iloc[i, j]),\n",
    "            font = dict(color = \"white\" if cm.iloc[i, j] > cm.values.max() / 2 else \"black\"),\n",
    "            showarrow = False\n",
    "        )\n",
    "\n",
    "fig.update_layout(title_text = \"Confusion Matrix - Logistic Regression (Spark)\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "31c0d397b1d3434e82908a35af06b69b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1681745635725,
    "source_hash": "7b8a6e51"
   },
   "outputs": [],
   "source": [
    "# Print the accuracy, precision, recall and f1 of the model\n",
    "print(\"Accuracy: %.4f\" % accuracy)\n",
    "print(\"Precision: %.4f\" % precision)\n",
    "print(\"Recall: %.4f\" % recall)\n",
    "print(\"F1: %.4f\" % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d858c701ec934289b9994381321733e0",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## 3. OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "cfd5a2a997044d2d82f5e810c13402a2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Initially, it may be a good idea just to test the OpenAI API with a very small sample of 100 transactions (50 fraudulent and 50 non-fraudulent). This can be achieved, as follows:\n",
    "\n",
    "```\n",
    "new_pdf = pdf.groupby(\"Class\").sample(n = 50)\n",
    "```\n",
    "\n",
    "The cost for this should be approximately US$0.39 (39 cents).\n",
    "\n",
    "Subsequently, if you decide to use the full 3265 rows, you can just copy the Dataframe, as follows:\n",
    "\n",
    "```\n",
    "new_pdf = pdf.copy()\n",
    "```\n",
    "\n",
    "The cost for this should be approximately US$13 (13 dollars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4efc46ec59bc491eb633d13c8e1b29ef",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1681745836643,
    "source_hash": "1c2c06ba"
   },
   "outputs": [],
   "source": [
    "# Cost US$00.39 for 100\n",
    "new_pdf = pdf.groupby(\"Class\").sample(n = 50)\n",
    "\n",
    "# Cost US$13.00 for 3265\n",
    "# new_pdf = pdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "98b4f708a1f14ff79f21140f1819d938",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1681745849838,
    "is_code_hidden": false,
    "source_hash": "d5eedef1"
   },
   "outputs": [],
   "source": [
    "my_key = \"<Add your OpenAI Key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d5618fdf092e4e3390f3c2d0836d5629",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The following code handles rate limits, which occur with the free credits. The code is adapted from a [notebook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_handle_rate_limits.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "611ea82f09b8427eab0a73ee68f29eca",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1681745852371,
    "source_hash": "3db65d44"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import openai\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = my_key\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "\n",
    "@retry(wait = wait_random_exponential(min = 1, max = 60),\n",
    "       stop = stop_after_attempt(6)\n",
    ")\n",
    "\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return openai.Completion.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2156d4f62a3a4a14ace5b41034a73a3b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1681745855424,
    "source_hash": "bb94dcb1"
   },
   "outputs": [],
   "source": [
    "data = new_pdf.values.tolist()\n",
    "\n",
    "# Split the data into features and labels\n",
    "features = [[float(cell) for cell in row[1:29]] + [float(row[29])] for row in data]\n",
    "labels = [int(row[-1]) for row in data]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size = 0.3,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5f8afd2b772149169d715ab8c3422e0a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "In the next code block to execute the code, comment out the following line, as follows:\n",
    "\n",
    "```\n",
    "# raise KeyboardInterrupt(\"Execution stopped manually.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3f6ee8cdea2549baa4885b88b2bf8e9c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1172423,
    "execution_start": 1681311378206,
    "output_cleared": false,
    "source_hash": "eabf1e70"
   },
   "outputs": [],
   "source": [
    "raise KeyboardInterrupt(\"Execution stopped manually.\")\n",
    "\n",
    "# Train the model\n",
    "train_model = \"text-davinci-002\"\n",
    "train_prompt = (\n",
    "    f\"The goal of this task is to train a model to classify transactions \\n\"\n",
    "    f\"as fraudulent or not based on historical data. Each transaction is \\n\"\n",
    "    f\"represented by 28 features (the details of which are not available) \\n\"\n",
    "    f\"and the monetary value of the transaction in the last column. The \\n\"\n",
    "    f\"label for each transaction is either 0 indicating that it is not \\n\"\n",
    "    f\"fraudulent, or 1 indicating that it is fraudulent. Your task is to use \\n\"\n",
    "    f\"the OpenAI GPT-3 API to train a model to classify transactions as \\n\"\n",
    "    f\"fraudulent or not. Please classify the following transactions as either \\n\"\n",
    "    f\"not fraudulent or fraudulent.\"\n",
    ")\n",
    "\n",
    "train_model_response = completion_with_backoff(\n",
    "    engine = train_model,\n",
    "    prompt = train_prompt,\n",
    "    temperature = 0.5,\n",
    "    max_tokens = 30,\n",
    "    n = 1,\n",
    "    stop = None,\n",
    "    timeout = 30,\n",
    ")\n",
    "\n",
    "train_model_id = train_model_response.model\n",
    "\n",
    "for i in range(len(train_features)):\n",
    "    prompt = (f\"Train the model to classify the transaction with the following \\n\"\n",
    "              f\"label: {train_labels[i]}, with features: {train_features[i]}\"\n",
    "    )\n",
    "    response = completion_with_backoff(\n",
    "        engine = train_model_id,\n",
    "        prompt = prompt,\n",
    "        temperature = 0.5,\n",
    "        max_tokens = 30,\n",
    "        n = 1,\n",
    "        stop = None,\n",
    "        timeout = 30,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1fa8ccf25d2343a582cbdad6d0170411",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1681312590583,
    "source_hash": "698bdd35"
   },
   "outputs": [],
   "source": [
    "# Save the train model to disk\n",
    "train_model = openai.Model(train_model_id)\n",
    "with open(\"models/train_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "23004b4aba524f79b86009e2e117a81a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 18,
    "execution_start": 1681745868433,
    "source_hash": "224a409a"
   },
   "outputs": [],
   "source": [
    "# Check that the train model can be read back from disk\n",
    "with open(\"models/train_model.pkl\", \"rb\") as f:\n",
    "    train_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ed5c1014ef5846408419473b5885297e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "In the next code block to execute the code, comment out the following line, as follows:\n",
    "\n",
    "```\n",
    "# raise KeyboardInterrupt(\"Execution stopped manually.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "954d2827df4c4903922a09f295ba7fea",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 444199,
    "execution_start": 1681745880538,
    "output_cleared": false,
    "source_hash": "b54dd2cb"
   },
   "outputs": [],
   "source": [
    "raise KeyboardInterrupt(\"Execution stopped manually.\")\n",
    "\n",
    "# Evaluate the model\n",
    "test_model = train_model\n",
    "test_model_prompt = (\n",
    "    f\"Classify whether the transaction with the following features is \\n\"\n",
    "    f\"either not fraudulent or fraudulent.\"\n",
    ")\n",
    "\n",
    "test_model_response = completion_with_backoff(\n",
    "    engine = train_model.id,\n",
    "    prompt = test_model_prompt,\n",
    "    temperature = 0.5,\n",
    "    max_tokens = 30,\n",
    "    n = 1,\n",
    "    stop = None,\n",
    "    timeout = 30,\n",
    ")\n",
    "\n",
    "test_model_id = test_model_response.model\n",
    "\n",
    "predicted_labels = []\n",
    "for i in range(len(test_features)):\n",
    "    prompt = (f\"Classify whether the transaction with the following features is \\n\"\n",
    "              f\"either not fraudulent or fraudulent: {test_features[i]}\"\n",
    "    )\n",
    "    response = completion_with_backoff(\n",
    "        engine = test_model_id,\n",
    "        prompt = prompt,\n",
    "        temperature = 0.5,\n",
    "        max_tokens = 30,\n",
    "        n = 1,\n",
    "        stop = None,\n",
    "        timeout = 30,\n",
    "    )\n",
    "\n",
    "    predicted_label = response.choices[0].text.strip().lower().replace(\".\", \"\")\n",
    "    binary_label = 1 if predicted_label == \"fraudulent\" else 0\n",
    "    predicted_labels.append(binary_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6e5d3240d6d34256908f8bc57cd8217b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1681746346019,
    "source_hash": "9e34f617"
   },
   "outputs": [],
   "source": [
    "# Save the test model to disk\n",
    "test_model = openai.Model(test_model_id)\n",
    "with open(\"models/test_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8c25d439b34547898293bc34881af047",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1681746348810,
    "source_hash": "755097d7"
   },
   "outputs": [],
   "source": [
    "# Check that the test model can be read back from disk\n",
    "with open(\"models/test_model.pkl\", \"rb\") as f:\n",
    "    test_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "81c25590364a4fe8a7a5714f297a0f3d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 59,
    "execution_start": 1681746351844,
    "source_hash": "2458e7d6"
   },
   "outputs": [],
   "source": [
    "# Generate and plot the confusion matrix\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "fig = px.imshow(\n",
    "    cm,\n",
    "    x = [\"Genuine (0)\", \"Fraudulent (1)\"],\n",
    "    y = [\"Genuine (0)\", \"Fraudulent (1)\"],\n",
    "    color_continuous_scale = \"Reds\",\n",
    "    labels = dict(x = \"Predicted Label\", y = \"True Label\")\n",
    ")\n",
    "\n",
    "# Add annotations to the heatmap\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm)):\n",
    "        fig.add_annotation(\n",
    "            x = j,\n",
    "            y = i,\n",
    "            text = str(cm[i][j]),\n",
    "            font = dict(color = \"white\" if cm[i][j] > cm.max() / 2 else \"black\"),\n",
    "            showarrow = False\n",
    "        )\n",
    "\n",
    "fig.update_layout(title = \"Confusion Matrix - OpenAI Model\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9d627dd76ab94ca7bd6e7a3cee0b6b67",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 63,
    "execution_start": 1681746361820,
    "source_hash": "7d6c50f1"
   },
   "outputs": [],
   "source": [
    "# Calculate and print the accuracy, precision, recall and f1 of the model\n",
    "report = classification_report(test_labels, predicted_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f2f3669be9f24b53bc34aa5f0c5dc487",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f7f8fbdea2fb406abf75955cadc79812",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "- GPT and similar technologies can augment existing ML/DL\n",
    "  - Useful to analyse text, such as email messages, to detect potential fraud\n",
    "- Fine-tuning could help\n",
    "  - [Fine tuning classification example](https://github.com/openai/openai-cookbook/blob/main/examples/Fine-tuned_classification.ipynb)\n",
    "- Finding working examples could be a challenge\n",
    "  - Technology is moving very fast\n",
    "  - Older examples may no longer work\n",
    "  - [OpenAI Cookbook](https://github.com/openai/openai-cookbook)\n",
    "- Care with privacy and personal information\n",
    "  - Use fake/mock data\n",
    "- Think carefully about prompt design\n",
    "  - Test initially on small scale\n",
    "  - Save your models\n",
    "  - Watch the costs and manage your budget\n",
    "  ![Used_Punchcard](images/Used_Punchcard.jpg)\n",
    "  Source: [Wikipedia](https://en.wikipedia.org/wiki/Punched_card)"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "211bd45d036144689197ad8a9b29bf27",
  "deepnote_persisted_session": {
   "createdAt": "2023-04-18T04:02:44.905Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
